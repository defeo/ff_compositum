\documentclass{sig-alternate}

\usepackage{bm}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{alltt, amssymb,stmaryrd}
\usepackage{color}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\C {\ensuremath{\mathsf{C}}}
\def\M {\ensuremath{\mathsf{M}}}
\def\Q {\ensuremath{\mathbb{Q}}}
\def\N {\ensuremath{\mathbb{N}}}
\def\R {\ensuremath{\mathbb{R}}}
\def\Z {\ensuremath{\mathbb{Z}}}
\def\F {\ensuremath{\mathbb{F}}}
\def\H {\ensuremath{\mathbb{H}}}
\def\K {\ensuremath{\mathbb{K}}}
\def\Kbar {\ensuremath{\overline{\mathbb{K}}}}
\def\L {\ensuremath{\mathbb{L}}}
\def\A {\ensuremath{\mathbb{A}}}
\def\B {\ensuremath{\mathbb{B}}}

\def\va {\ensuremath{\mathsf{a}}}
\def\vu {\ensuremath{\mathsf{u}}}
\def\vb {\ensuremath{\mathsf{b}}}
\def\vc {\ensuremath{\mathsf{c}}}

\def\mul {\ensuremath{\mathrm{mul}}}
\def\div {\ensuremath{\mathrm{div}}}
\def\rem {\ensuremath{\mathrm{rem}}}
\def\cat {\ensuremath{\mathrm{cat}}}
\def\coeff {\ensuremath{\mathrm{coefficient}}}
\def\mulmod {\ensuremath{\mathrm{mulmod}}}
\def\rev {\ensuremath{\mathrm{rev}}}
\def\x {\ensuremath{\mathbf{x}}}
\def\Tr {\ensuremath{\mathrm{Tr}}}
\DeclareBoldMathCommand{\bgamma}{\gamma}
\DeclareBoldMathCommand{\bbeta}{\eta}
\DeclareBoldMathCommand{\bbbeta}{\beta}
\DeclareBoldMathCommand{\blambda}{\lambda}

\newcommand{\wrt}{\vdash} 
\newcommand{\ang}[1]{\langle#1\rangle}
\newcommand{\dual}[1]{\overline{#1}}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}

\newtheorem{Def}{Definition}
\newtheorem{Theo}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{Lemma}{Lemma}

\numberofauthors{3}
\author{
  \alignauthor Luca De Feo\\
  \affaddr{Laboratoire PRiSM}\\
  \affaddr{Universit\'e de Versailles}\\
  \email{luca.de-feo@uvsq.fr}
  \alignauthor Javad Doliskani\\
  \affaddr{Computer Science Department}\\
  \affaddr{Western University}\\
  \email{jdoliska@uwo.ca}
  \alignauthor \'Eric Schost\\
  \affaddr{Computer Science Department}\\
  \affaddr{Western University}\\
  \email{eschost@uwo.ca}
}

\title{Fast arithmetic for the algebraic closure of finite fields}

\begin{document}

\maketitle
\begin{abstract}
  This paper presents algorithms to construct and perform arithmetic
  operations in the algebraic closure of the finite field
  $\mathbb{F}_p$. Our approach is inspired by algorithms for
  constructing irreducible polynomials, which first reduce to prime
  power degrees, then use composita techniques. We use similar ideas to
  give efficient algorithms for embeddings and isomorphisms.
\end{abstract}

\category{F.2.1}{Theory of computation}{Analysis of algorithms and problem complexity}[Computations in finite fields]
\category{G.4}{Mathematics of computing}{Mathematical software}
\terms{Algorithms,Theory}
\keywords{Finite fields, irreducible polynomials, extensions.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

We denote by $\M:\N \to \N$ a function such that for any ring $A$,
polynomials in $A[x]$ of degree at most $n$ can be multiplied in
$\M(n)$ operations $(+,\times)$ in $A$, and we make the usual
super-linearity assumptions on $\M$~\cite[Chapter~8]{vzGG}. We also
denote by $\omega$ a constant in $(2,3]$ such that one can multiply
  matrices of size $n$ over $A$ using $O(n^\omega)$ operations
  $(+,\times)$ in $A$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}

We recall first previous results concerning basic polynomial
arithmetic and duality. 

In all this section, the ground field $k$ is fixed. The following
notation will be useful: given variables $x_1,\dots,x_s$ and integers
$d_1,\dots,d_s$, $k[x_1,\dots,x_s]_{d_1,\dots,d_s}$ denotes the set of
polynomials $P$ in $k[x_1,\dots,x_s]$ such that $\deg(P,x_i) < d_i$
holds for all $i$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Polynomial multiplication and remainder}

We start be describing some classical algorithms and their complexity.
For $b$ in $k[x]$ of degree at most $m$, it will be convenient to let
$$
\begin{array}{cccc}
\mul(.,b,m,n): &k[x]_n& \to &k[x]_{k+n}\\
& a & \mapsto & ab
\end{array}$$ 
denote the multiplication-by-$b$ operator, which can be applied using
$\M(\max(m,n))$ operations in $k$. In a similar vein, we denote by
$$
\begin{array}{cccc}
\rev(.,m): &k[x]_m &\to& k[x]_m  \\
& a & \mapsto & x^{m-1} a(1/x)
\end{array}$$ the reversal operator. 
Next, fix a monic polynomial $P$ of degree $m$ in $k[x]$. For $n \ge 1$, we denote by
$\rem(.,P,n)$ the operator
$$
\begin{array}{cccc}
\rem(.,P,n): &k[x]_n& \to &k[x]_{m}\\
& a & \mapsto & a \bmod P.
\end{array}$$ 
Such remainders can be computed in time $O(\M(\max(n,m)))$ using the
Cook-Sieveking-Kung algorithm~\cite[Chapter~9]{vzGG}. For $b$
in $k[x]/\ang{P}$ we will also use the modular multiplication
operator
$$\begin{array}{cccc} \mulmod(.,b,P): & k[x]/\ang{P} & \to
  & k[x]/\ang{P}\\ & a & \mapsto & ab \bmod P.
\end{array}$$ 
Identifying $k[x]_m$ and $k[x]/\ang{P}$, and using the
direct algorithm for modular multiplication (multiply, then reduce),
we can write 
\begin{equation}
  \label{eq:mulmod}
  \mulmod(.,b,P) = \rem(.,P,2m-1) \circ \mul(.,b,m-1,m).
\end{equation}
One can thus compute $\mulmod(a,b,P)$ using $O(\M(m))$ operations in
$k$, as is well known.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The transposition principle}
\label{sec:algor-dual-basis}

The {\em transposition principle} is an algorithmic theorem which
states that given an algorithm that performs an $r \times s$
matrix-vector product $u \mapsto M u$, one can deduce an algorithm
with the same cost, up to $O(\max(r,s))$, which performs the
transposed matrix-vector product $v \mapsto M^t
v$~\cite[Chapter~13]{burgisser+clausen-shokrollahi}; see~\cite{Ka2K}
for historical notes.

Although that theorem is constructive, the proof involves going down
to the DAG representation of the algorithm, which is hardly
convenient.  In the rest of this article, we will reuse techniques
from~\cite{bostan+lecerf+schost:tellegen} in order to simplify the
transposition process: in a nutshell, most of our algorithms will rely
on a few basic operations (such as polynomial or matrix
multiplication), and their transposes are obtained by transposing each
such basic subroutine and reversing their order.

If $M$ represents a $k$-linear mapping $E \to F$, its transpose can
naturally be seen as a $k$-linear mapping between the dual spaces $F^*
\to E^*$ (other interpretations will be discussed below). We will
often work with vector spaces such as $k[x]_m$, represented on the
standard polynomial basis $(x^i)_{i<m}$; its dual space $k[x]_m^\ast$
is identified with $k^m$.

%% Mutliplication by a fixed $b\in k[x]_m$ is a linear map
%% \begin{equation*}
%%   M_b: k[x]_n \to k[x]_{m+n}
%% \end{equation*}
%% for any positive integer $n$. By definition, its \emph{dual} (or
%% \emph{transpose}, especially when talking about algorithms) is a
%% linear map
%% \begin{equation*}
%%   M_b^t : k^{m+n} \to k^n
%% \end{equation*}
%% such that
%% \begin{equation*}
%%   \ang{\ell,M_b(a)} = \ang{\ell,ab} = \ang{M_b^t(\ell),a}.
%% \end{equation*}

We will briefly review the transposes of the operations described in
the previous subsection, and we give pseudo-code for those that cannot
be found in standard references such as~\cite{vzGG}, or that are not
available in standard computer algebra systems.

For $b$ in $k[x]$ of degree at most $m$, $\mul^t(.,b,m,n)$ denotes the
transposed of the multiplication-by-$b$ mapping introduced above. To
implement it, one can use transposed versions of plain, Karatsuba and
FFT
algorithms~\cite{bostan+lecerf+schost:tellegen,hanrot+quercia+zimmermann},
which have the same running time, up to an extra $O(m)$.  By
identifying $k[x]_n$ with its dual, one can also see $\mul^t(.,b,m,n)$
mapping $k[x]_{m+n}$ to $k[x]_{n}$ and notice that $\mul^t(.,b,m,n)$
then becomes $$a \in k[x]_{m+n} \mapsto (a\ \rev(b,m+1) \bmod
x^{m+n}){\rm~div~}x^{m} \in k[x]_n.$$ This formula leads to algorithms
for the transposed product that can be implemented using only
``classical'' polynomial multiplication, but are slower than those
of~\cite{bostan+lecerf+schost:tellegen,hanrot+quercia+zimmermann} by a
constant factor.

The reversal operator on $k[x]_m$ is its own dual. Finally, we
consider $A=k[x]/\ang{P}$, with $P$ monic of degree $m$, and we
discuss the tranposes of $\rem$ and $\mulmod$.  For the moment, we
work in the \emph{monomial basis} of $A$, which is made up of the
monomials $x^i$ for $0\le i<m$.  As shown
in~\cite{bostan+lecerf+schost:tellegen}, the dual map
$$
\begin{array}{cccc}
\rem^t(.,P,n): &k^m& \to &k^n
\end{array}$$ 
takes as input a linear form $\ell\in A^\ast$ expressed on the dual
basis (that is, given by the values $(\ell(x^i))_{0 \le i <m}$; the
output is then the values $(\ell(x^i))_{0 \le i < k}$. For $n \le m$,
there is nothing to do. For greater values of $n$, $\rem^t$ is
\emph{linear sequence extension}: it takes as input the initial $m$
values of a linear recurring sequence of minimal polynomial $P$, and
outputs its first $n$ values.

LFSRs give a simple, though suboptimal, implementation of this
operator. The transposed version of the Cook-Sieveking-Kung fast
Euclidean division algorithm yield better algorithms: as for the
forward direction the cost of the transposed algorithm is $O(\M(n))$
if $n>m$. We recall this below.

\begin{algorithm}[H]
  \caption{$\rem^t(\ell,P,n)$}
  \begin{algorithmic}[1]
    \REQUIRE $\ell=(\ell_i)_{0 \le i < m}$, $P$ in $k[x]$ monic of degree $m$, $n \ge m$
    \STATE $S = 1/\rev(P, m+1) \bmod x^{n-m}$
    \STATE $a = \mul^t( \sum_{0 \le i < m} \ell_{i}x^i, P, m, n-m)$
    \STATE $c = S a \bmod x^{n-m}$
    \STATE $d = \ell ~\cat~ (-\coeff(c,i))_{0 \le i < n-m}$
    \RETURN $d$
  \end{algorithmic}
\end{algorithm}

Finally, multiplication by a fixed $b\in A$ is a linear map $M_b:A\to
A$. By definition, the dual map $M_b^t: A^* \to A^*$ maps a linear
form to $b \cdot \ell$, which is such that $(b \cdot \ell)(a)
=\ell(ab)$.  

Algorithms for $\mulmod^t$ have been subject to much
research (for instance, Berlekamp's \emph{bit serial
  multiplication}~\cite{Berlekamp82} is a popular arithmetic circuit
for transposed modular multiplication in the case $k=\F_2$, with
quadratic complexity). From Eq.~\eqref{eq:mulmod}, we obtain the
following algorithm $\mulmod^t$, costing $O(\M(m))$ operations in
$k$~\cite{shoup99,bostan+lecerf+schost:tellegen}.

%% \begin{equation}
%%   \label{eq:mulmodt-def}
%%   \ang{M_b^t(a),c}_P = \ang{a,M_b(c)}_P = \ang{a,bc}_P = \tau_P(abc).
%% \end{equation}
%% Hence, if $a$ is written on the dual basis, the transposed map
%% $\mulmod^t(.,b,P)$ maps a linear form $\ell = a\cdot\tau_P$ to the
%% linear form $b \cdot \ell=ab\cdot\tau_P$.  

\begin{algorithm}[H]
  \caption{$\mulmod^t(\ell,b,P)$}
  \begin{algorithmic}[1]
    \STATE $\ell' = \rem^t(\ell,P,2m-1)$
    \RETURN $\mul^t(\ell', b, m-1, m)$
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Trace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Duality}\label{ssec:duality}

We continue with some classical facts about dualities induced by
non-degenerate bilinear forms. A general reference for what follows
is~\cite[Ch.~IX.1.8]{BourbakiAlgCom9}.

Let $E$ and $F$ be finite dimensional $k$-vector spaces, with
$\dim(E)=\dim(F)$; suppose further that $\Phi$ is a non-degenerate
$k$-linear form $E\times F \to k$. Then, to any $k$-vector space basis
$\bgamma=(\gamma_i)_i$ of $E$, we can associate a unique \emph{dual basis}
$\bgamma^\ast=(\gamma_i^\ast)_i$ of $F$ such that
\begin{equation}
  \label{eq:dual-basis}
  \Phi(\gamma_i,\gamma^\ast_i) = \begin{cases} 1 &\text{if $i=j$,}\\ 0
    &\text{otherwise}.
  \end{cases}
\end{equation}
In other words, given $a$ in $F$, the coefficients $(a_i)$ of $a$ on
the basis $\bgamma^\ast$ are given by $a_i=\Phi(\gamma_i, a)$. A
standard example (implicitly used in the previous section) is the case
where $F$ is the dual $E^*$ of $E$, with $\Phi(v,\ell)=\ell(v)$ for
all $v\in E$ and $\ell \in E^*$; we will see in the next subsection
another family of examples, with $E=F$.

Let $E',F'$ be two further vector spaces, with $\dim(E')=\dim(F')$ and
let $\Phi'$ be a $k$-bilinear form $E'\times F' \to k$. Then, to any
$k$-linear mapping $u:E\to E'$, one associates its {\em dual} (with
respect to $\Phi$ and $\Phi'$), which is a $k$-linear mapping $u^t: F'
\to F$ characterized by the equality $\Phi'(u(a),b')=\Phi(a,u^t(b'))$,
for all $a\in E$ and $b'$ in $F'$.  

Let as above $\bgamma$ be a basis of $E$, and let $\bgamma^\ast$ be
the dual basis of $F$. Similarly, consider a basis $\bbeta$ of $E'$
and its dual basis $\bbeta^\ast$ of $E'$. Then, if $M$ is the matrix
of $u$ in the bases $(\bgamma,\bbeta)$, the matrix of $u^t$ in the
bases $(\bbeta^\ast,\bgamma^\ast)$ is the transpose of $M$.

The transposition principle then implies that, given an algorithm that
computes $u: E \to E'$ in the bases $(\bgamma,\bbeta)$, we deduce the
existence of an algorithm for the dual map $u^t: F' \to F$, expressed
in the bases $(\bbeta^\ast,\bgamma^\ast)$, with essentially the same
cost.
 
%% Given an algorithm for $\mulmod^t$ one can multiply two elements
%% represented on the dual basis by converting one to the monomial basis,
%% and then applying $\mulmod^t$. Since $\mulmod^t$ has the same cost as
%% $\mulmod$~\cite{shoup99,bostan+lecerf+schost:tellegen}, this is better
%% than converting both elements to the monomial basis.
%% Much research has gone in finding polynomials $P$ that make the
%% conversion between the monomial and the dual basis cheap. An open
%% question is whether there exists a better algorithm to multiply two
%% elements directly in the dual basis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Traces in reduced algebras}

A general reference for all the following
is~\cite{Cox-Little-OShea:UAG2005}. Suppose in this subsection that
$k$ is a {\em perfect} field, $s$ a positive integer, and $I$ a zero
dimensional radical ideal in $k[x_1,\dots,x_s]$; thus,
$A=k[x_1,\dots,x_s]/I$ is a reduced $k$-algebra of finite dimension
$d$, where $d$ is the cardinality of $V=V(I) \subset\overline{k}^s$
(but in general, $A$ is not a field).

Let $a$ be in $A$. As we did in the case of one variable we associate
to $a$ the endomorphism of multiplication-by-$a$ $M_a: A \to A$ given
by $M_a(b)=ab$.  Even though $A$ may not be a field, we may still
define the {\em minimal polynomial} of $a$ (in the extension $A/k$) as
the minimal polynomial of $M_a$; since $I$ is radical, this polynomial
is squarefree, with roots $a(x)$, for $x$ in $V$. Similarly, we define
the \emph{trace} of $a$ as the trace of $M_a$, and denote it by
$\tau_I(a)$; then, we have
\begin{equation}\label{eq:tr}
\tau_{I}(a)=\sum_{\x \in V} a(\x),
\end{equation}
Thanks again to $I$ being radical, the trace defines a non-degenerate
bilinear form on $A\times A$
\begin{equation}
  \label{eq:trace-def}
  \ang{a,b}_I = \tau_I(ab).
\end{equation}
Thus, to any basis $\bgamma=(\gamma_i)_{0 \le i < d}$ of $A$, one can
associate a dual basis $\bgamma^\ast=(\gamma^\ast_i)_{0 \le i < d}$,
such that $\tau_I(\gamma_i \gamma^\ast_j)=\delta_{i,j}$ for all $i,j$.
It will be useful to keep in mind that for $a \in A$, its expression
on the dual basis $\bgamma^\ast$ is $a=\sum_{0 \le i < d} \tau_I(a
\gamma_i) \gamma^\ast_i$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conversion algorithms} \label{ssec:conversions}
\label{sec:trace-formulas}

We now describe algorithms for converting between the monomial and its
dual, in two particular cases, involving respectively of univariate
and bivariate polynomials. In both cases, our conclusion will be that
such conversions have quasi-linear complexity.

\paragraph*{{\bf \rm Univariate conversion}} Let $P$ be monic of degree $m$ 
and squarefree in $k[x]$, and define $A=k[x]/\ang{P}$. We denote by
$\tau_P$ the trace modulo $P$.

The $k$-algebra $A$ is endowed with the canonical monomial basis
$\bgamma=(x^i)_{0 \le i < m}$.  In this case, conversion algorithms
between the monomial basis and its dual $\bgamma^\ast$ are essentially
well-known (though usually not stated in these terms). Indeed, in view
of what was said in the previous subsection, the coefficients of an
element $a \in A$ on the dual basis are the traces $\tau_P(ax^i)_{0
  \le i < m}$.  The following lemma shows that the generating series
of these traces is rational, with a known denominator; this will be
the key to the conversion algorithm. This is a restatement of
well-known results, see for instance the proof
of~\cite[Theorem~3.1]{rouiller99}.

\begin{Lemma}\label{lemma:trace:1}
  For $a=\sum_{0 \le i < m} a_i x^i$ in $A$, the following equality
  holds in $k[[x]]$:
  $$\sum_{i \ge 0} \tau_P(a x^i) x^i = \frac{\rev( P' a \bmod P,m)}{\rev(P,m+1)}.$$
\end{Lemma}

The conversion algorithms follow easily. 

\begin{algorithm}[H]
  \caption{MonomialToDual$(\va, P)$}
  \begin{algorithmic}[1]
    \REQUIRE $\va=(a_i)_{0 \le i < m} \in k^m$ \\
    $P$ monic squarefree in $k[x]$ of degree $m$
    \ENSURE $(\tau_P(a x^i))_{0 \le i < m}$, with $a=\sum_{0 \le i < m} a_i x^i$
    \STATE $T = 1/\rev(P, m+1) \bmod x^m$
    \STATE\label{algo:minpolytotrace:1} $b = \rev(P' \sum_{0 \le i < m} a_i x^i \bmod P, m) T \bmod x^m$
    \RETURN $(\coeff(b,i))_{0 \le i < m}$
  \end{algorithmic}
  \label{algo:minpolytotrace}
\end{algorithm}

\begin{algorithm}[H]
  \caption{DualToMonomial$(\vb, P)$}
  \begin{algorithmic}[1]
    \REQUIRE $\vb=(b_i)_{0 \le i < m} \in k^m$\\
    $P$ monic squarefree in $k[x]$ of degree $m$
    \ENSURE $(a_i)_{0 \le i < m}$ such that $\tau_P(\sum_{0 \le i < m} a_i x^{i+j}) = b_j$
    \STATE $S = 1/P' \bmod P$
    \STATE $b= \rev(P,m+1) \sum_{0 \le i < m} b_i x^i \bmod x^m$
    \STATE $c= \rev(b, m)$
    \STATE\label{algo:minpolytotrace:1} $d =c S \bmod P$
    \RETURN $(\coeff(d,i))_{0 \le i < m}$
  \end{algorithmic}
  \label{algo:tracetopoly}
\end{algorithm}

\begin{Lemma}\label{lemma:uniconv}
  Algorithms~\ref{algo:minpolytotrace} and~\ref{algo:tracetopoly} are
  correct. The former uses $O(\M(m))$ operations in $k$, and the
  latter $O(\M(m)\log(m))$.  If the polynomial $S=1/P' \bmod P$ is
  known, the running time of Algorithm~\ref{algo:tracetopoly} drops to
  $O(\M(m))$.
\end{Lemma}
\begin{proof}
  Correctness follows from Lemma~\ref{lemma:trace:1}.  The running
  time analysis is straightforward; for
  Algorithm~\ref{algo:tracetopoly}, the dominant part is the
  computation of $S$, which takes time $O(\M(m)\log(m))$ by fast XGCD;
  all other steps take $O(\M(m))$ operations in $k$.
\end{proof}

\paragraph*{{\bf \rm Bivariate conversions}} Let now $P,Q$ be monic of respective 
degrees $m$ and $n$, and squarefree, in respectively $k[x]$ and
$k[y]$, and define $A=k[x,y]/I$, with $I=\ang{P,Q}$; we denote by
$\tau_I$ the trace modulo $I$. Remark that $A$ has the canonical
monomial basis $(x^i y^j)_{0 \le i <m, 0 \le j < n}$ (so we may
identify $A$ and $k[x,y]_{m,n}$). For $a$ in $k[x,y]$, $a \bmod I$
denotes the polynomial in $k[x,y]_{m,n}$ obtained by reduction modulo
both $P$ and $Q$.

In addition to its monomial basis, $A$ can be endowed with a total of
four natural bases, which are described as follows. Let
$\bgamma=(x^i)_{0 \le i < m}$ and $\bbeta=(y^i)_{0 \le j < n}$ be the
monomial bases of respectively $k[x]/\ang{P}$ and $k[y]/\ang{Q}$; let
$\bgamma^\ast$ and $\bbeta^\ast$ be their respective dual bases, with
respect to $\tau_P$ and $\tau_Q$. The monomial basis seen above is
$\bgamma \cdot \bbeta$; the other combinations $\bgamma^\ast \cdot
\bbeta$, $\bgamma \cdot \bbeta^\ast$ and $\bgamma^\ast \cdot
\bbeta^\ast$ are bases of $A$ as well. The following easy lemma will
help us exhibit the duality relationships between them; it follows
from the fact that $A$ is the tensor product of $k[x]/\ang{P}$ and
$k[y]/\ang{Q}$.

\begin{Lemma}
  \label{lemma:traces:PQR1}
  Let $b$ be in $k[x]/\ang{P}$ and $c$ in $k[y]/\ang{Q}$. Then we have
  $\tau_I(bc) = \tau_P(b) \ \tau_Q(c)$.
\end{Lemma}

This lemma readily implies that $\bgamma \cdot \bbeta$ and
$\bgamma^\ast \cdot \bbeta^\ast$ are dual to one another with respect
to $\tau_I$, as are $\bgamma^\ast \cdot \bbeta$ and $\bgamma \cdot
\bbeta^\ast$. 

After a precomputation of cost $O(\M(m)\log(m) + \M(n)\log(n))$,
Lemma~\ref{lemma:uniconv} shows that conversions between any pair of
these dual bases can be done using $O(n\M(m)+m\M(n))$ operations in
$k$. Using fast multiplication, this quasi-linear in the dimension
$mn$ of $A$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Embedding and isomorphism} 

In this section, we consider two squarefree polynomials $P(x)$ and
$Q(y)$ of respective degrees $m$ and $n$, with coefficients in a
perfect field $k$. Let us then set $A=k[x,y]/I$, where $I$ is the
ideal $\ang{P(x),Q(y)}$ in $k[x,y]$. In all this section, {\em we
  assume that $xy$ is a generator of $A$ as a $k$-algebra}. The
following lemma gives a sufficient condition for this to be the case.

\begin{Lemma}
  \label{lemma:compositum}
  Let $(\alpha_i)_{i<m}$ be the roots of $P$ in an algebraic closure
  of $k$, and let $(\beta_i)_{i<n}$ be the roots of $Q$. Assume that
  the elements $\alpha_i\beta_j$ are pairwise distinct. Then $xy$
  generates $A$ as a $k$-algebra.
\end{Lemma}
\begin{proof}
  The assumption implies that the eigenvalues of the
  multiplication-by-$xy$ map of $A$ are pairwise distinct; the result
  the follows (for instance) from~\cite[Prop.~2.2.12]{DiEm05}.
\end{proof}

The main example we have in mind is the following: $k$ is a finite
field and both $P$ and $Q$ are irreducible, with $\gcd(m,n)=1$; then,
the assumptions of the lemma are satisfied. In addition, in this case,
$A$ is a field (namely, $A$ is the {\em compositum} of the fields
$k[x]/\ang{P}$ and $k[y]/\ang{Q}$), see~\cite{BrCa87}; however, in
what follows, we do not need to assume that $A$ be a field.

Let $R(z)$ be the minimal polynomial of $xy$ in the extension $A/k$, so
that as $k$-algebras we have $A \simeq k[x]/\ang{R}$. Then, we have
embeddings of the form
$$\begin{array}{cccc}
\varphi_x: & k[x]/\ang{P} & \to & k[z]/\ang{R}\\
& x & \mapsto & S
\end{array}$$
and
$$\begin{array}{cccc}
\varphi_y: & k[y]/\langle Q \rangle & \to & k[z]/\ang{R}\\
& y & \mapsto & T,
\end{array}$$
for some polynomials $S$ and $T$ in $k[z]$ of degrees less
than $mn$. We also have an isomorphism of the form
$$\begin{array}{cccc} 
\Phi:&  A=k[x,y]/\langle P,Q\rangle & \to & k[z]/\ang{R} \\
&  x & \mapsto & S \\
&  y & \mapsto & T \\
&  xy & \mapsfrom & z.
\end{array}$$

In what follows, we discuss algorithms for computing $R$, then
applying $\varphi_x$ and $\varphi_y$ as well as their inverses (when
well-defined), as well as $\Phi$ and its inverse. Except from the
computation of $R$, these are all linear algebra problems. 

If $R,S,T$ are known, then a direct solution is available: modular
composition. For instance assuming $S=\varphi_x(x)$ is known,
$\varphi_x(F)$ is computed as $G=F(S) \bmod R$. Using Brent and Kung's
modular composition techniques~\cite{brent+kung}, this can be done in
$O(n m^{(\omega+1)/2})$ operations in $k$, since we evaluate a
polynomial of degree $m$ modulo the polynomial $R$ of degree $mn$ (see
the analysis in~\cite{shoup94}).

We take a different path. One of the key aspects of our algorithms is
that some of them are written in the usual monomial bases of
respectively $k[x]/\ang{P}$, $k[y]/\ang{Q}$, $k[z]/\ang{R}$, whereas
others are naturally expressed in the corresponding dual bases. From
the complexity point of view, this is not an issue, since we saw that
all change-of-bases can be done in quasi-linear time.
%%  To write the algorithms, we use the following conventions: to
%% stress the fact that an element say $a\in A$ is represented on the
%% dual basis, we will write $\dual{a}$ (when an element, such as $1$,
%% may belong to more than one algebra, we add a subscript like in
%% $\dual{1}_P, \dual{1}_R, \dots$ to remove ambiguities).

In what follows, we write $\tau_P,\tau_Q,\tau_R,\tau_I$ for the traces
modulo the ideals $\ang{P}\subset k[x]$, $\ang{Q} \subset k[y]$,
$\ang{R} \subset k[z]$ and $I=\ang{P,Q} \subset k[x,y]$. 

It will also be useful to denote by $\bgamma=(x^i)_{0 \le i < m}$,
$\bbeta=(y^i)_{0 \le j < n}$ and $\bbbeta = (z^i)_{0 \le i < mn}$ the
monomial bases of respectively $k[x]/\ang{P}$, $k[y]/\ang{Q}$ and
$k[z]/\ang{R}$. We let $\bgamma^\ast=(\gamma^\ast_i)_{0 \le i <m}$,
$\bbeta^\ast=(\eta^\ast_i)_{0 \le i < n}$ and
$\bbbeta^\ast=(\beta^\ast_i)_{0 \le i < mn}$ be their dual bases, with
respect to respectively $\tau_P$, $\tau_Q$ and $\tau_R$.

Finally, we denote by $\vu_P \in k^m$ the vector of the coordinates of
$1 \in k[x]/\ang{P}$ on the dual basis $\bgamma^\ast$; the vector
$\vu_Q$ is defined similarly. These vectors can both be computed in
quasi-linear time, since we have, for instance, $\vu_P = {\rm
  MonomialToDual}((1,0,\dots,0), P)$. Thus, in what follows, we assume
that these vectors are known.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Embedding and computing $R$} 

We first show how to compute the embeddings $\varphi_x$ and
$\varphi_y$, and their inverses in quasi-linear time in $mn$. We
actually give a slightly more general algorithm, which computes the
restriction of $\Phi$ to the set $$\Pi= \{bc \,\mid\, b\in
k[x]/\ang{P},\ c\in k[y]/\ang{Q}\} \subset A=k[x,y]/\ang{P,Q}.$$ We
will use the following lemma, which results from the base independence
of the trace (the second equality is Lemma~\ref{lemma:traces:PQR1}).
\begin{Lemma}
  \label{lemma:traces:PQR}
  Let $b$ be in $k[x]/\ang{P}$ and $c$ in $k[y]/\ang{Q}$. Then we have
  $\tau_R(\Phi(bc)) = \tau_I(bc) = \tau_P(b) \ \tau_Q(c)$.
\end{Lemma}
An easy consequence is that $\tau_R(z^i) =
\tau_P(x^i)\tau_Q(y^i)$. From this, we immediately deduce
Algorithm~\ref{algo:embed}, which computes the image in $k[z]/\ang{R}$
of any element of $\Pi$, with inputs and outputs written on the dual
basis.

\begin{algorithm}[H]
  \caption{Embed$(\vb,\vc,\ell)$}
  \begin{algorithmic}[1]
    \REQUIRE $\vb=(b_i)_{0 \le i < m} \in k^m$, $\vc=(c_i)_{0 \le i < n} \in k^n$\\
    an optional integer $\ell \ge mn$ set to $\ell=mn$ by default
    \ENSURE $\va=(a_i)_{0 \le i < \ell} \in k^{\ell}$
    \STATE $(t_i)_{0\le i<\ell} = \rem^t(\vb,P,\ell)$
    \STATE $(u_i)_{0\le i<\ell} = \rem^t(\vc,Q,\ell)$
    \RETURN $(t_i u_i)_{0 \le i <\ell}$
  \end{algorithmic}
  \label{algo:embed}
\end{algorithm}

\begin{Lemma}\label{lemma:algo:embed}
  Given $\vb=(b_i)_{0 \le i < m}$ and $\vc = (c_i)_{0 \le i < n}$,
  define $b=\sum_{0 \le i<m} b_i \gamma^\ast_i$ and $c=\sum_{0 \le j
    <n} c_i \eta^\ast_i$. Then, calling {\em Embed}$(\vb,\vc,\ell)$
  computes $(a_i)_{0 \le i < \ell}=(\tau_R(\Phi(bc)z^i)_{0 \le i <
    \ell}$ using $O(\M(\ell))$ operations in $k$. In particular, if
  $\ell=mn$, the equality $\sum_{0 \le i < mn} a_i \beta^\ast_i =
  \Phi(bc)$ holds.
\end{Lemma}
\begin{proof}
  Recall that for $0 \le i <m$, $b_i = \tau_P(bx^i)$, and that for $0
  \le i < n$, $c_i = \tau_Q(cy^i)$. By definition of $\rem^t$, the
  sequences $(t_i)$ and $(u_i)$ encode the same traces, but up to
  index $\ell$.  By Lemma~\ref{lemma:traces:PQR}, the algorithm
  computes
  \begin{eqnarray*}
    \bigl(\tau_P(bx^i)\tau_Q(cy^i)\bigr)_{i<\ell} &=&  \bigl(\tau_R(\Phi(bc x^i y^i))\bigr)_{i<\ell}\\
    &=&  \bigl(\tau_R(\Phi(bc) z^i))\bigr)_{i<\ell},
  \end{eqnarray*}
  as claimed; for $\ell=mn$, this is exactly the representation of
  $\Phi(bc)$ on the dual basis of $k[z]/\ang{R}$. As explained in
  Section~\ref{sec:algor-dual-basis}, the two calls to $\rem^t$ take
  time $O(\M(\ell))$. Then, the last step takes $\ell$
  multiplications in $k$.
\end{proof}

In particular, the map $\varphi_x$ is computed as
Embed$(\cdot,\vu_Q)$, and the map $\varphi_y$ as
Embed$(\vu_P,\cdot)$. Another interesting consequence is that, when
$A$ is known to be a field, Algorithm Embed allows us to compute $R$,
using the Berlekamp-Massey algorithm.

\begin{algorithm}[H]
  \caption{ComputeR$(P,Q)$}
  \begin{algorithmic}[1]
    \REQUIRE $P$ in $k[x]$, $Q$ in $k[y]$
    \ENSURE $R$ in $k[z]$
    \STATE $(t_i)_{0 \le i < 2mn}={\rm Embed}(\vu_P,\vu_Q,2mn)$,
    \RETURN BerlekampMassey$((t_i)_{0 \le i < 2mn})$
  \end{algorithmic}
  \label{algo:R}
\end{algorithm}

Indeed, in this case, Embed$(\vu_P,\vu_Q,2mn)$ computes the sequence
$(\tau_R(z^i))_{0\le i < 2mn}$. If we know that $A$ is a field, $R$ is
irreducible, so the minimal polynomial of this sequence (which is the
output of our call to the Berlekamp-Massey algorithm) is precisely
$R$; the running time of this process is $O(\M(mn)\log(mn))$
operations in $k$. This algorithm for computing $R$ is well-known; see
for instance~\cite{BoFlSaSc06} for a variation using power series
exponentials instead of Berlekamp-Massey's algorithm (that applies in
large enough characteristic) and~\cite{BGPS05} for the specific case
of finite fields of small characteristic.


For the inverse of $\varphi_x$, we take $a$ in $k[z]/\langle R
\rangle$ of the form $a=\varphi_x(b)$, and compute $b$. Using the
equality of Lemma~\ref{lemma:traces:PQR} in the form $\tau_P(b x^i)
=\tau_R(a z^i)/\tau_Q(y^i)$ would lead to a simple algorithm, but some
traces $\tau_Q(y^i)$ may vanish. We take a different path, instead.

Let $c$ be a fixed element in $k[y]/\ang{Q}$ such that $\tau_Q(c)=1$;
a natural choice for $c$ is the first element $\eta^\ast_0$ of the
dual basis of $k[y]/\ang{Q}$, but this is not necessary.

Let us denote by $\epsilon: k[x]/\ang{P} \to k[z]/\ang{R}$ the mapping
defined by $\epsilon(b) = \Phi(b c)$, and let $\epsilon^t:
k[z]/\ang{R} \to k[x]/\ang{P}$ be its dual map with respect to the
bilinear forms $\tau_R$ and $\tau_P$. Then, for any $b$ and $b'$ in 
$k[x]/\ang{P}$, we have
\begin{eqnarray*}
\tau_P(b b') &=&  \tau_P(b b')\tau_Q(c) \\
&=& \tau_R( \Phi(b b' c))\\
&=& \tau_R( \epsilon(b) \Phi(b')) \\
&=& \tau_P(b \epsilon^t(\Phi(b'))),
\end{eqnarray*}
where the second equality comes from
Lemma~\ref{lemma:traces:PQR}. Hence, using the non-degeneracy of
$\tau_P$, we deduce $\epsilon^t(\Phi(b')) = b'$, or equivalently
$\epsilon^t(\varphi_x(b')) = b'$. Thus, $\epsilon^t$ gives an 
inverse of $\varphi_x$ on its image.

In what follows, we take for $c$ the first element of the dual basis
of $k[y]/\ang{Q}$. Keeping $c$ fixed, we see that Algorithm Embed
precisely computes the mapping $b\mapsto \epsilon(b)$. Since Embed is
written in the dual bases, the discussion of
Section~\ref{ssec:duality} shows that transposing this algorithm (with
respect to $b$) yields an algorithm for $\epsilon^t$ written in the
monomial bases. This leads to Algorithm~\ref{algo:inverseEmbed}.

\begin{algorithm}[H]
  \caption{Project$(\va)$}
  \begin{algorithmic}[1]
    \REQUIRE $\va=(a_i)_{0 \le i < mn} \in k^{mn}$
    \ENSURE $\vb=(b_i)_{0 \le i < m} \in k^m$
    \STATE $\vc=(1,0,\dots,0)$ 
    \STATE $(u_i)_{0\le i<mn} = \rem^t(\vc,Q,mn)$
    \STATE\label{algo:inverseEmbed:dotprod} $d = \sum_{i=0}^{mn-1} a_i u_i x^i  \bmod P$
    \RETURN\label{algo:inverseEmbed:mod} $(\coeff(d,i))_{0 \le i < m}$
  \end{algorithmic}\label{algo:inverseEmbed}
\end{algorithm}

\begin{Lemma}
  Given $\va=(a_i)_{0 \le i < mn}$, define $a=\sum_{0 \le i < mn} a_i
  z^i$. If $a$ is in the image of $\varphi_x$, then calling {\em
    Project}$(\va)$ computes $(b_i)_{0 \le i < m}$ such that
  $a=\varphi_x(\sum_{0 \le i < m} b_i x^i)$ using $O(\M(mn))$
  operations in $k$.
\end{Lemma}
\begin{proof}
  We show correctness using transposition techniques as
  in~\cite{bostan+lecerf+schost:tellegen}. Observe that for fixed
  $\vc$, Embed$(\vb,\vc)$ is linear in $\vb$ and can be written as
  $\pi_\vc\circ\rem^t$, where $\pi_\vc$ is the map that multiplies a
  vector in $k^{mn}$ coefficient-wise by $(\tau_Q(c y^i))_{i<mn}$, for
  $c=\sum_{0 \le i < n} c_i \eta^\ast_i$.  Hence, its transpose is
  $\rem\circ\pi_\vc^t$. It is evident that $\pi_\vc^t=\pi_\vc$ (since
  $\pi_\vc$ is a diagonal map), whereas $\rem$ is just reduction
  modulo $P$. These correspond to
  steps~\ref{algo:inverseEmbed:dotprod}
  and~\ref{algo:inverseEmbed:mod}. The discussion above now proves
  that the output is $\epsilon^t(a)$. The cost analysis is similar to
  the one in Lemma~\ref{lemma:algo:embed}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Isomorphism} 

We continue with algorithms for computing the isomorphism $\Phi$.  We
are not able to give an algorithm for $\Phi$ that would be as
efficient as those for embedding; instead, we provide two such
algorithms, with different domains of applicability. In all that
follows, without loss of generality, {\em we assume that $n\le m$}.

Recall that $\bgamma \cdot \bbeta$,\ $\bgamma^\ast \cdot
\bbeta$,\ $\bgamma \cdot \bbeta^\ast$ and $\bgamma^\ast \cdot
\bbeta^\ast$ are four possible bases of $A$, with $(\bgamma \cdot
\bbeta, \bgamma^\ast \cdot \bbeta^\ast)$ and $(\bgamma^\ast \cdot
\bbeta, \bgamma \cdot \bbeta^\ast)$ being two pairs of dual bases with
respect to $\tau_I$. Our algorithms will exploit all these bases; this
is harmless, since conversions between these bases have quasi-linear
complexity.

Before giving the details of the algorithms, we make the following
further observation, similar to the one we did regarding the transpose
of Embed above. Let $\Phi^t$ be the dual map of $\Phi$ with respect to
$\tau_R$ and $\tau_I$. Then, for any $b,b' \in k[z]/\ang{R}$, we have:
\begin{eqnarray*}
\tau_I(b b') &=&  \tau_R(\Phi(b b'))\\
&=& \tau_R( \Phi(b) \Phi(b')) \\
&=& \tau_I(b\, \Phi^t(\Phi(b')));
\end{eqnarray*}
hence, $\Phi^t = \Phi^{-1}$. Let then ${\bf b}$ and ${\bf b}^\ast$ be
two bases of $A=k[x,y]/I$, dual with respect to $\tau_I$ (such as the
ones seen above); let as well ${\bf c}$ and ${\bf c}^\ast$ be two
bases of $k[z]/\ang{R}$, dual with respect to $\tau_R$. The previous
equality, together with the transposition principle, shows the
following: if we have an algorithm for $\Phi$, expressed in the bases
${\bf b}$ and ${\bf c}$, transposing it yields an algorithm for
$\Phi^{-1}$, expressed in the bases ${\bf b}^\ast$ and~${\bf c}^\ast$.

\paragraph*{{\bf \rm First case: $n$ is small}}
We start by a direct application of the results in the previous
subsection, which is well-suited to situations where $n$ is small
compared to $m$.

Let $b$ be in $k[x,y]/I$ and let $a=\Phi(b)$. Writing $b=\sum_{0 \le i
  < n} b_i y^i$, with all $b_i$ in $k[x]/\ang{P}$, we obtain a
straightforward algorithm to compute $a$: compute all $\Phi(b_iy^i)$,
using Algorithm~\ref{algo:embed}, then sum.

Since Algorithm~\ref{algo:embed} takes its inputs written on the dual
basis of $k[x]/\ang{P}$, the following algorithm requires all $b_i$ be
written this way (equivalently, the input is given on the basis
$\bgamma^\ast \cdot \bbeta$ of $A$). We use the further observation
that the expression of $y^i$ on the dual basis $\bbeta^\star$ is
$\vu_Q$ shifted by $i$ positions to give a slightly more compact
algorithm.

\begin{algorithm}[H]
  \caption{Phi1$(\vb)$}
  \begin{algorithmic}[1]
    \REQUIRE $\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$
    \ENSURE $\va = (a_{i})_{0 \le i < mn} \in k^{m n}$
    \STATE $(u_i)_{0\le i < (m+1)n-1} = \rem^t(\vu_Q,Q,(m+1)n-1)$
    \STATE $(a_i)_{0\le i < mn} = (0,\dots,0)$
    \FOR {$0\le j < n$}
    \STATE $(t_i)_{0\le i < mn} = \rem^t( (b_{i,j})_{0 \le i <m}  ,P,mn)$
    \STATE $(a_i)_{0\le i < mn} = (a_i + t_iu_{i+j})_{0\le i < mn}$
    \ENDFOR
    \RETURN $(a_i)_{0\le i <mn}$
  \end{algorithmic}
  \label{algo:iso1}
\end{algorithm}

\begin{Lemma}
  Given $\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n}$ in $k^{m \times
    n}$, define $b=\sum_{0 \le i<m, 0 \le j < n} b_{i,j} \gamma^\ast_i
  y^j$. Then, calling {\em Phi1}$(\vb)$ computes $(a_i)_{0 \le
    i < mn}$ such that $\sum_{0 \le i < mn} a_i \beta^\ast_i =
  \Phi(b)$ holds using $O(n^2\M(m))$ operations in~$k$.
\end{Lemma}
\begin{proof}
  \todo{The analysis can be improved to $O(n^2\M(m))$ by observing
    that $\rem$ and $\rem^t$ can use unbalanced multiplication.}
\end{proof}

Transposing the previous algorithm, we obtain an algorithm for
$\Phi^{-1}$. The input is now expressed on the monomial basis
$(z^i)_{0 \le i < mn}$ of $k[z]/\ang{R}$, and the output is expressed
on the basis $\bgamma \cdot \bbeta^\ast$ of $A$.

\begin{algorithm}[H]
  \caption{InversePhi1$(\va)$}
  \begin{algorithmic}[1]
    \REQUIRE $\va = (a_{i})_{0 \le i < mn} \in k^{m n}$
    \ENSURE  $\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$
    \STATE $(u_i)_{0\le i < (m+1)n-1} = \rem^t(\vu_Q,Q,(m+1)n-1)$
    \STATE $(b_{i,j}) = (0)_{0\le i < m, 0 \le j < n}$
    \FOR {$j = n-1,\dots,0$}
    \STATE $d=\sum_{0 \le i < mn} a_i u_{i+j} x^i \bmod P$
    \STATE $(b_{i,j})_{0 \le i < m} = (\coeff(d,i))_{0 \le i < m}$
    \ENDFOR
    \RETURN $(b_{i,j})_{0 \le i < m, 0 \le j < n}$
  \end{algorithmic}
  \label{algo:iso1}
\end{algorithm}

\begin{Lemma}
  Given $\va = (a_{i})_{0 \le i < mn}$ in $k^{m n}$, define $a=\sum_{0
    \le i<mn} a_i z^i$. Then, calling {\em InversePhi1}$(\va)$
  computes coefficients $(b_{i,j})_{0 \le i < m, 0 \le j < n}$ such
  that $\sum_{0 \le i < m, 0 \le j < n} b_{i,j} x^i \eta^\ast_j =
  \Phi^{-1}(a)$ using $O(n^2\M(m))$ operations in~$k$.
\end{Lemma}

\paragraph*{{\bf \rm First case: $n$ is not small}}
The previous algorithm is most efficient when $n$ is small; now, we
propose an alternative solution that does better when $m$ and $n$ are
of the same order of magnitude.

This approach is based on baby steps / giant steps techniques, as in
Brent and Kung's modular composition algorithm, but uses the fact that
$Z=\Phi(XY)$ to reduce the cost. Given $F$ in $\F[X,Y]/\langle
P,Q\rangle$, let us write
\begin{eqnarray*}
F&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} f_{i,j}X^i Y^j\\
&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} f_{i,j}X^i Y^i Y^{j-i}\\
&=&\sum_{k=-m+1}^{n-1}\sum_{i=0}^{m-1} f_{i,i+k}(XY)^i Y^k\\
&=&\frac{1}{Y^{m-1}} \sum_{k=0}^{m+n-2} H_k(XY) Y^k,
\end{eqnarray*}
with $H_k(Z)=\sum_{0 \le i < m-1} f_{i,i+k-m+1} Z^i$ for all $k$.
This implies that $G=\Phi(F)$ has the form
$$G = \frac{1}{T^{m-1}}\widetilde{G} \mod R\quad\text{with}\quad
\widetilde{G}=\sum_{k=0}^{m+n-2} H_k T^k.$$ We use baby steps / giant
steps techniques from~\cite{LeMeSc13} (inspired by Brent and Kung's
algorithm) to compute $G$, reducing the problem to polynomial matrix
multiplication. Let
$$n'=m+n-1,\quad p=\lceil \sqrt {n'} \rceil,\quad q=\lceil
n'/p\rceil,$$ so that $n \le n' \le 2n-1$ and $p\simeq q \simeq
\sqrt{n}$.  For baby steps, we compute the polynomials $T_i=T^i \bmod
R$, which have degree at most $mn-1$; we write $T_i = \sum_{0 \le j <
  n} T'_{i,j} Z^{jm}$, with $T'_{i,j}$ of degree less than $m$, and
build the polynomial matrix $M_{T'}$ with entries $T'_{i,j}$.  We also
define the matrix $M_H=[H_{iq+j}]_{0 \le i <p, 0 \le j < q}$
containing the polynomials $H_k$ organized in a row-major fashion, and
compute the product $M_V=M_H M_T$. We can then recompose polynomials
from the rows of $M_V$, and conclude with giant steps, using Horner's
scheme to obtain $G$.
\begin{algorithm}[H]
  \caption{ChangeBasis2$(F,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
    \STATE\label{iso2:2} $T={\rm Embed}(Y,Q,R)$
    \STATE\label{iso2:3} $U=1/T \bmod R$
    \STATE\label{iso2:4} $T'=[T^i \bmod R]_{0 \le i < q}$
    \STATE $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
    \STATE $M_H=[H_{iq+j}]_{0 \le i <p, 0 \le j < q}$ \hfill $H_k$ as defined above
    \STATE\label{iso2:7} $M_V = M_H M_{T'}$
    \STATE $V=[\sum_{0 \le j <n} {M_V}_{i,j} Z^{jm} ]_{0 \le i <p}$
    \STATE $V^*=[V_i \bmod R]_{0 \le i <p}$
    \STATE $G=0$
    \FOR{$i=p-1,\dots,0$}\label{iso2:11}
    \STATE $G=T^qG+V^*_i \bmod R$
    \ENDFOR
    \STATE\label{iso2:14} $G=G U^{m-1} \bmod R$
    \RETURN $G$
  \end{algorithmic}
  \label{algo:iso2}
\end{algorithm}

\begin{Lemma}
  Algorithm~\ref{algo:iso2} correctly computes $\Phi(F)$ using
  $O(\M(m) n^{(\omega+1)/2} )$ operations in~$\F$.
\end{Lemma}
\begin{proof}
  Remark first that $n'=O(n)$, and that $p$ and $q$ are both
  $O(\sqrt{n})$. Steps~\ref{iso2:2},~\ref{iso2:3} and~\ref{iso2:14}
  cost $O(\M(mn)\log(mn))$ operations. Steps~\ref{iso2:4} (the baby
  steps) and the loop at Step~\ref{iso2:11} (the giant steps) cost
  $O(\sqrt{n}\M(mn))$. The dominant cost is the matrix product at
  Step~\ref{iso2:7}, which involves matrices of size $O(\sqrt{n})
  \times O(\sqrt{n})$ and $O(\sqrt{n}) \times O(n)$, with polynomial
  entries of degree $m$: this takes $O(\M(m) n^{(\omega+1)/2})$ 
  operations in $\F$.
\end{proof}

As before, we will need the transpose of this algorithm (todo: more
explanations).
\begin{algorithm}[H]
  \caption{ChangeBasis2$^t(\gamma,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
    \STATE $T={\rm Embed}(Y,Q,R)$
    \STATE $U=1/T \bmod R$
    \STATE $T'=[T^i \bmod R]_{0 \le i < q}$
    \STATE $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
    \STATE $\gamma = \mulmod^t(\gamma, U^{m-1}, R)$
    \STATE $V^*=[\ ]_{0 \le i < p}$
    \FOR{$i=0,\dots,p-1$}
    \STATE $V^*_i = \gamma$
    \STATE $\gamma = \mulmod^t(\gamma,T^q,R)$
    \ENDFOR
    \STATE $V = [\rem^t(V^*_i,R,mn+m-1)]_{0 \le i < p}$
    \STATE $M_V = [(V_{i})_{jm,\dots,jm+2m-1}]_{0 \le i < p, 0 \le j < n}$
    \STATE $M_H = \mul^t(M_V, M_{T'})$
    \STATE $H=[{M_H}_{0,0},\dots,{M_H}_{0,q-1},\dots,{M_H}_{p-1,q-1}]$
    \STATE $\ell=[\coeff(H_{i-j+m-1},i)]_{0 \le i < m, 0 \le j < n}$
    \RETURN $\ell$
  \end{algorithmic}
  \label{algo:tiso2}
\end{algorithm}


\paragraph{Summary.} For $m \le n$, and neglecting logarithmic factors,
our two solutions for $\Phi$ (or its inverse) have respective costs
$O\tilde{~}(m^2 n)$ and $O\tilde{~}(m n^{(\omega+1)/2})$. Writing
$\delta=mn$, the minimum of the two is
$O\tilde{~}(\delta^{2\omega/(\omega+1)})$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Computing in the algebraic closure of $\F_p$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Prerequisites}

\paragraph{Towers}
Suppose that for any prime $\ell$, an $\ell$-adic tower over $\F_p$ is
known. By this, we mean a family of polynomials $(T_{\ell,i})_{i \ge
  1}$, with $T_{\ell,i} \in \F_p[X_1,\dots,X_i]$, monic of degree
$\ell$ in $X_i$, such that the ideal $\langle
T_{\ell,1},\dots,T_{\ell,i} \rangle$ is prime in
$\F_p[X_1,\dots,X_i]$. From these polynomials, we can in particular
deduce further families of polynomial $Q_{\ell,i}$ monic, irreducible
of degree $\ell^i$ in $\F_p[X_j]$ and for $j > i$, $Q_{\ell,i,j}
\in\F_p[X_i,X_j]$, monic of degree $\ell^{j-i}$ in $X_j$, irreducible
in $\F_p[X_i]/\langle Q_{\ell,i}\rangle[X_j]$. We assume that all
these polynomials are known free of cost.

For $i,j$ as above, $\F_p[X_i]/\langle Q_{\ell,i} \rangle$ is a field
with $p^{\ell^i}$ elements, which will be our model for
$\F_{p^{\ell^i}}$. Similarly, $\F_p[X_j]/\langle Q_{\ell,j}\rangle$ is
our model for the field with $p^{\ell^j}$ elements; another model is
$\F_p[X_i,X_j]/\langle Q_{\ell,i}, Q_{\ell,i,j}\rangle$.

\paragraph{Composed products.} In addition, we assume that given a finite field
$\K$, and irreducible polynomials $P$ and $Q$ in $\K[X]$, we can
compute the composed product $R = P \otimes Q$, and perform the
related embedding and change of basis operations, as in the previous
section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The general construction}

\paragraph{Setup.} For $\ell$ prime and $i \ge 1$, define
$\K_{\ell^i}=\F_p[X_1,\dots,X_i]/\langle
T_{\ell,1},\dots,T_{\ell,i}\rangle$. This is a field with $\ell^i$
elements.  The residue class of $X_i$ in $\K_{\ell^i}$ will be written
$x_{\ell^i}$.

Fix a positive integer $m=\ell_1^{e_1}\cdots \ell_r^{e_r}$, with
$\ell_i$ pairwise distinct primes and $e_i$ positive integers.  Define
$\K_m$ as the tensor product $\K_{\ell_1^{e_1}} \otimes \cdots \otimes
\K_{\ell_r^{e_r}}$; this is a field with $p^m$ elements.  If $m$
divides $n$, then $\K_m$ embeds in $\K_n$. Taking the direct limit of
all $\K_m$ under such embeddings, we get an algebraic closure $\K$ of
$\F_p$. The residue classes written $x_{\ell^i}$ in $\K_{\ell^i}$ all
lie in $\K$ and are still written $x_{\ell^i}$.

For any integer $n$ of the form $n=\ell_1^{c_1}\cdots \ell_s^{c_s}$
with $\ell_i$ pairwise distinct primes, we write $x_n =
x_{\ell_1^{c_1}} \cdots x_{\ell_s^{c_s}} \in \K$.



\paragraph{Minimal polynomials.}
First, we discuss minimal polynomials of (residue classes of)
monomials, either over $\F_p$ or over an intermediate field.

Consider a residue class $x_{\ell^{c}}$, with $\ell$ a prime. Its
minimal polynomial over $\F_p$ is $Q_{\ell^c}=Q_{\ell,c}(Z)$,
irreducible of degree $\ell^{c}$ in $\F_p[Z]$. Next, consider the term
$x_m$, with $m=\ell_1^{e_1}\cdots \ell_r^{e_r}$, with all $\ell_i$'s
pairwise distinct primes. This term equals $x_{\ell_1^{e_1}} \cdots
x_{\ell_r^{e_r}}$, so it is a root of $Q_{m}=Q_{\ell_1^{e_1}} \otimes
\cdots \otimes Q_{\ell_r^{e_r}}.$ Since $Q_m$ is irreducible of degree
$m=\ell_1^{e_1}\cdots \ell_r^{e_r}$ in $\F_p[Z]$, it is the minimal
polynomial of $x_m$.  In particular, this last fact implies that
$\F_p(x_m)$ is a field with $p^m$ elements, and that if we consider
terms $x_m$ and $x_n$, with $m$ dividing $n$, then $x_m$ is in
$\F_p(x_n)$.

Conversely, with $m$ and $n$ as above, we are now going to describe
the minimal polynomial of $x_n$ over $\F_p(x_m)$. Without loss of
generality, we can assume that $m$ and $n$ are written
$m=\ell_1^{e_1}\cdots \ell_r^{e_r}$ and
$n=\ell_1^{g_1}\cdots\ell_r^{g_r}$, with $e_i \le g_i$ for all $i$.
The minimal polynomial of $x_{\ell_i^{g_i}}$ over
$\F_p(x_{\ell_i^{c_i}})$ is $Q_{\ell_i,c_i,g_i}(x_{\ell_i^{c_i}},Z)$.
Since $\F_p(x_m)$ is an extension of $\F_p(x_{\ell_i^{c_i}})$ of
degree coprime to $\ell_i$, and since the former polynomial has degree
$\ell_i^{g_i-c_i}$, it remains irreducible in $\F_p(x_m)[Z]$. We
deduce that the minimal polynomial of $x_n = x_{\ell_1^{g_1}}\cdots
x_{\ell_r^{g_r}}$ over $\F_p(x_m)$ is $Q_{m,n}=Q_{\ell_1,c_1,g_i}
\otimes \cdots \otimes Q_{\ell_r,c_r,g_r}.$ It has degree
$n/m=\ell_1^{g_1-c_1}\cdots \ell_r^{g_r-c_r}$.

\paragraph{Embedding and change of basis.} Consider a sequence $d=(d_1,\dots,d_s)$ 
of positive integers, and let $m=d_1 \cdots d_s$. The set
$$B_d = \{ x_{d_1}^{e_1} x_{d_1 d_2}^{e_2} \cdots x_{d_1 \cdots
  d_s}^{e_1} \mid 0 \le e_i < d_i \}$$ is a basis of $\F(x_m)$. Our
main examples are sequences of the form $d=(d_1)$, with thus $m=d_1$,
for which $B_d$ is the univariate basis $(x_m^i)_{0 \le i < m}$.

Consider two such sequences $d=(d_1,\dots,d_s)$ and
$e=(e_1,\dots,e_t)$, with $m=d_1 \cdots d_s$ and $n=e_1 \cdots e_t$,
and suppose that $m$ divides $n$. The embedding $\F_p^{B_d} \to
\F_p^{B_e}$ is denoted by $\Phi_{e,d}$; when $m=n$, it is an
isomorphism, with inverse $\Phi_{d,e}$.

As soon as this expression makes sense, we have $\Phi_{f,d} =
\Phi_{f,e}\circ \Phi_{e,d}$.

\paragraph{Basic algorithms.}
Let us now examine how to apply mappings such as $\Phi_{e,d}$.
Suppose that $d=(d_1,\dots,d_s)$. Then, the following operations are
available to us:
\begin{itemize}
\item[$A_1$] Suppose that $\gcd(d_i,d_{i+1})=1$, and let $e$ be
  obtained from $d$ by swapping $d_i$ and $d_{i+1}$. Then $\Phi_{e,d}$
  is a permutation.
\item[$A_2$] Suppose that $e$ is obtained by replacing $d_i$ by $d'_i,
  d''_i$, with $d_i = d'_i d''_i$ and $\gcd(d'_i,d''_i)=1$. Then one
  can compute $\Phi_{e,d}$, or $\Phi_{d,e}$, by applying the change of
  basis algorithm, or its inverse, with coefficients in
  $\F_p^{B_c}$, with $c=(d_1,\dots,d_{i-1})$.
\item[$A_3$] Suppose that $e$ is obtained by replacing $d_i$ by $d_i
  d'_i$, with $\gcd(d_i, d'_i)=1$. Then one can compute $\Phi_{e,d}$,
  or invert it when possible, by applying the embedding algorithm,
  with coefficients in $\F_p^{B_c}$, with $c=(d_1,\dots,d_{i-1})$.
\item[$A_4$] Suppose that $d_1=\ell^{e_1}$ and $d_2=\ell^{e_2}$, for some
  prime $\ell$, and that $e$ is obtained by replacing $d_1,d_2$ by
  $d_1 d_2=\ell^{e_1+e_2}$. Then one can compute $\Phi_{e,d}$, or
  $\Phi_{d,e}$, by applying the $\ell$-adic change of basis algorithm,
  or its inverse. 
\item[$A_5$] Suppose that $d_1=\ell^{e_1}$, for some prime $\ell$, and that
  $e$ is obtained by replacing $d_1$ by $\ell^{e_1+e_2}$. Then one can
  compute $\Phi_{e,d}$, invert it when possible, by applying the
  $\ell$-adic embedding algorithm, or its inverse. 
\end{itemize}

\paragraph{Concrete procedures.} Suppose that $m$ divides $n$. We 
describe here how to embed $\F_p(x_m)$ in $\F_p(x_n)$, that is, how to
compute $\Phi_{(n),(m)}$. Write $m= \ell_1^{f_1}\cdots \ell_r^{f_r}$
and $n = n' \ell_1^{e_1}\cdots \ell_r^{e_r}$, where all $\ell_i$ are
primes and $\gcd(m,n')=1$; in particular, $f_i \le e_i$ holds for all
$i$.

Let $d=(\ell_1^{f_1},\dots,\ell_r^{f_r})$. Applying $A_2$ repeatedly,
we can compute $\Phi_{d,(m)}$. For $i=1,\dots,r$, do the following:
apply $A_1$ as needed to bring the factor $\ell_i^{f_i}$ to the first
position, then $A_5$ to replace $\ell_i^{f_i}$ by $\ell_i^{e_i}$ and
finally $A_1$ again to put that term back at $i$th position; this
allows us to compute $\Phi_{d',d}$, with
$d'=(\ell_1^{e_1},\dots,\ell_r^{e_r})$.  Apply $A_2$ repeatedly, to
compute $\Phi_{d'',d'}$, with $d''=(\ell_1^{e_1}\cdots\ell_r^{e_r})$.
Finally, use $A_3$ to compute $\Phi_{(n),d''}$.

Our second example is how to compute $\Phi_{(m,n), (mn)}$;
equivalently, how to convert from the univariate basis $(x_{mn}^i)_{i
  < mn}$ to the bivariate one $(x_m^i x_{mn}^j)_{i < m, j < n}$.

Write $m = m' \ell_1^{e_1}\cdots \ell_r^{e_r}$ and $n = n'
\ell_1^{f_1}\cdots \ell_r^{f_r}$, with
$\gcd(m',n')=\gcd(m',\ell_i)=\gcd(n',\ell_i)=1$ for all $i$; in
particular, $mn = m' n' \ell_1^{e_1+f_1}\cdots \ell_r^{e_r+f_r}$.
Apply $A_2$ in order to compute $\Phi_{d,(mn)}$, with $d =
(\ell_1^{e_1+f_1}\cdots\ell_r^{e_r+f_r}, m', n')$. As above, apply
repeatedly $A_1$, then $A_4$ and $A_1$, in order to compute
$\Phi_{d',d}$, with $d'=(\ell_1^{e_1},\dots, \ell_r^{e_r},
m',\ell_1^{f_1},\dots,\ell_r^{f_r}, n')$. Apply $A_2$ repeatedly
to compute $\Phi_{(m,n),d'}$.

With this, we can do $+,\times$ over the algebraic closure (embed the
operands in a common extension), relative characteristic and minimal
polynomials (and thus traces and norms), and probably most other
required operations.


\bibliographystyle{plain} \bibliography{defeo}

\end{document}




% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% mode:TeX-PDF
% mode:reftex
% End:

% LocalWords:  embeddings bilinear
